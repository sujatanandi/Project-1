{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data from the given raw file\n",
    "raw_dat = pd.read_csv('DSDataLastThreeMonths.csv')\n",
    "# removing null values for further analysis\n",
    "raw_dat = raw_dat.fillna(raw_dat.mean()).reset_index()\n",
    "data2 = raw_dat.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6697 entries, 0 to 6696\n",
      "Data columns (total 15 columns):\n",
      "index            6697 non-null int64\n",
      "CASTNO           6697 non-null object\n",
      "HM_WT            6697 non-null int64\n",
      "AIM_S            6697 non-null float64\n",
      "HM_S             6697 non-null float64\n",
      "HM_C             6697 non-null float64\n",
      "HM_SI            6697 non-null float64\n",
      "HM_TI            6697 non-null float64\n",
      "HM_MN            6697 non-null float64\n",
      "CAC2             6697 non-null int64\n",
      "MG               6697 non-null int64\n",
      "HM_TEMP          6697 non-null float64\n",
      "CAC2_INJ_TIME    6697 non-null int64\n",
      "MG_INJ_TIME      6697 non-null int64\n",
      "DS_S             6697 non-null float64\n",
      "dtypes: float64(8), int64(6), object(1)\n",
      "memory usage: 784.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean over whole data \n",
      " HM_WT             165.411229\n",
      "AIM_S               0.004969\n",
      "HM_S                0.039572\n",
      "HM_C                4.562660\n",
      "HM_SI               0.612587\n",
      "HM_TI               0.066564\n",
      "HM_MN               0.042735\n",
      "CAC2              354.522771\n",
      "MG                 50.390623\n",
      "HM_TEMP          1388.349688\n",
      "CAC2_INJ_TIME       9.372555\n",
      "MG_INJ_TIME         4.919068\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean = data2.loc[:,'HM_WT':'MG_INJ_TIME'].mean()\n",
    "print('mean over whole data','\\n',mean)\n",
    "data2.loc[:,'HM_WT':'MG_INJ_TIME'] -= mean\n",
    "sigma = raw_dat.loc[:,'HM_WT':'MG_INJ_TIME'].pow(2).mean()\n",
    "sigma = sigma.pow(0.5)\n",
    "# print(sigma)\n",
    "data2.loc[:,'HM_WT':'MG_INJ_TIME']/=sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dat = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the independent variable, X\n",
    "x_data = raw_dat.loc[:,['HM_WT', 'AIM_S', 'HM_S', 'HM_C', 'HM_SI', 'HM_TI','HM_MN', 'CAC2', 'MG', 'HM_TEMP', 'CAC2_INJ_TIME', 'MG_INJ_TIME']]\n",
    "# extracting the dependent variable, y\n",
    "y_data = raw_dat.loc[:,'DS_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tata_train(Dataset):\n",
    "\n",
    "    def __init__(self, X_train, y_train):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        y = self.y_train.iloc[idx]\n",
    "        z = int(y*1000)\n",
    "        yo=0\n",
    "        if z < 5:\n",
    "            yo = 0 #2\n",
    "        elif z < 10:\n",
    "            yo = 1 #7\n",
    "        elif z < 15:\n",
    "            yo = 2 #12\n",
    "        elif z < 20:\n",
    "            yo = 3 #17\n",
    "        elif z < 25:\n",
    "            yo = 4 #22\n",
    "        else:\n",
    "            print('zzz', z)\n",
    "\n",
    "        one_hot = np.zeros(5).astype('long')\n",
    "        idx2 = int(yo)\n",
    "        one_hot[idx2] = 1\n",
    "        return torch.tensor( self.X_train.iloc[idx] ), torch.tensor( one_hot )\n",
    "    def __len__(self):\n",
    "        return len(self.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "\n",
    "            nn.Linear(in_features = 12, out_features = 20),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            # nn.Sigmoid(),\n",
    "            # nn.BatchNorm1d(30),\n",
    "\n",
    "            nn.Linear(in_features = 20, out_features = 12),\n",
    "            nn.BatchNorm1d(12),\n",
    "            nn.ReLU(),\n",
    "            # nn.Sigmoid(),\n",
    "            # nn.BatchNorm1d(50),\n",
    "\n",
    "            nn.Linear(in_features = 12, out_features = 20),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            # # # nn.Sigmoid(),\n",
    "            # # nn.BatchNorm1d(50),\n",
    "            \n",
    "            nn.Linear(in_features = 20, out_features = 12),\n",
    "            nn.BatchNorm1d(12),\n",
    "            nn.ReLU(),\n",
    "            # # # nn.Sigmoid(),\n",
    "            # # nn.BatchNorm1d(30),\n",
    "\n",
    "            nn.Linear(in_features = 12, out_features = 20),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            # # # nn.Sigmoid(),\n",
    "            # # nn.BatchNorm1d(30),\n",
    "\n",
    "            nn.Linear(in_features = 20, out_features = 12),\n",
    "            nn.BatchNorm1d(12),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # nn.Linear(in_features = 30, out_features = 24),\n",
    "            nn.Linear(in_features = 12, out_features = 5), # for modified output\n",
    ")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tata_train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, shuffle=True, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=20, bias=True)\n",
      "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=20, out_features=12, bias=True)\n",
      "    (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=12, out_features=20, bias=True)\n",
      "    (7): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=20, out_features=12, bias=True)\n",
      "    (10): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=12, out_features=20, bias=True)\n",
      "    (13): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Linear(in_features=20, out_features=12, bias=True)\n",
      "    (16): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=12, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = Net().to(device)\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.03)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  loss  1.212038121449857\n",
      "epoch  1  loss  0.8423911449742327\n",
      "epoch  2  loss  0.7520475155851217\n",
      "epoch  3  loss  0.7297632903378827\n",
      "epoch  4  loss  0.7095057532769253\n",
      "epoch  5  loss  0.6976593416341967\n",
      "epoch  6  loss  0.6940045778208208\n",
      "epoch  7  loss  0.6899095164363638\n",
      "epoch  8  loss  0.6882186070170936\n",
      "epoch  9  loss  0.6865496848557499\n",
      "epoch  10  loss  0.6781594115232603\n",
      "epoch  11  loss  0.6768026422880294\n",
      "epoch  12  loss  0.6761618227072183\n",
      "epoch  13  loss  0.6718130607292475\n",
      "epoch  14  loss  0.6761551261532801\n",
      "epoch  15  loss  0.6794107558468969\n",
      "epoch  16  loss  0.6735018596976557\n",
      "epoch  17  loss  0.6749214312353147\n",
      "epoch  18  loss  0.6695565333124043\n",
      "epoch  19  loss  0.6597897135355725\n",
      "epoch  20  loss  0.6573631047564747\n",
      "epoch  21  loss  0.6494946308928944\n",
      "epoch  22  loss  0.6497376348841578\n",
      "epoch  23  loss  0.6489570381329945\n",
      "epoch  24  loss  0.6458777018386341\n",
      "epoch  25  loss  0.6472533648427554\n",
      "epoch  26  loss  0.6461492824968992\n",
      "epoch  27  loss  0.6448562133806495\n",
      "epoch  28  loss  0.6437172485790347\n",
      "epoch  29  loss  0.6465448712430998\n",
      "epoch  30  loss  0.6434192934899367\n",
      "epoch  31  loss  0.6426871024866058\n",
      "epoch  32  loss  0.6429765745565608\n",
      "epoch  33  loss  0.6413760607496628\n",
      "epoch  34  loss  0.6381189342699464\n",
      "epoch  35  loss  0.6410265916753336\n",
      "epoch  36  loss  0.642940948783315\n",
      "epoch  37  loss  0.6418852984400344\n",
      "epoch  38  loss  0.6392933098110194\n",
      "epoch  39  loss  0.6376381792822322\n",
      "epoch  40  loss  0.6395040862644245\n",
      "epoch  41  loss  0.6368506890665565\n",
      "epoch  42  loss  0.6360343571650998\n",
      "epoch  43  loss  0.6366268103536197\n",
      "epoch  44  loss  0.634642962786538\n",
      "epoch  45  loss  0.6369751508194477\n",
      "epoch  46  loss  0.6359038352434836\n",
      "epoch  47  loss  0.6380072324285537\n",
      "epoch  48  loss  0.6380892288615754\n",
      "epoch  49  loss  0.6369015039528155\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for _ in range(epochs):\n",
    "    scheduler.step()\n",
    "    running_loss = 0.0\n",
    "    for x , y in train_loader:\n",
    "        # print(x, y)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = net(x)\n",
    "\n",
    "        loss = criterion(out, torch.max(y,1)[1])\n",
    "        running_loss += loss.item()*y.size(0)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    running_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(running_loss)\n",
    "    print('epoch ', _ ,' loss ', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.from_numpy( np.array( X_train.loc[:,:]) ).float()\n",
    "test_tensor = torch.from_numpy( np.array( X_test.loc[:,:] ) ).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4486, 12])\n"
     ]
    }
   ],
   "source": [
    "#for moodified\n",
    "d = { 0 : 2.0 , 1 : 7.0 , 2 : 12.0 , 3 : 17.0 , 4 : 22.0} #best config till now\n",
    "print(train_tensor.size())\n",
    "pred_train = net(train_tensor.to(device)).to('cpu').detach().numpy().argmax(axis=1).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_train\n",
      " [12.  7.  7.  7.]\n"
     ]
    }
   ],
   "source": [
    "pred_train = np.array([d[x] for x in pred_train])\n",
    "print('pred_train\\n', pred_train[:4])\n",
    "pred_train /= 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified\n",
    "pred_test = net(test_tensor.to(device)).to('cpu').detach().numpy().argmax(axis=1).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_test\n",
      " [12.  2.  7.  7.]\n"
     ]
    }
   ],
   "source": [
    "pred_test = np.array([d[x] for x in pred_test])\n",
    "print('pred_test\\n', pred_test[:4])\n",
    "pred_test /= 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tolerance range\n",
    "check = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# finding the error on the predictions\n",
    "y_test = list(y_test)\n",
    "y_train = list(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = [x-y for x,y in zip(pred_test,y_test)]\n",
    "err_train = [x-y for x,y in zip(pred_train,y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the strike rates on the datasets\n",
    "strike_rate_test = 100*sum([np.abs(x)<=check for x in err_test])/len(err_test)\n",
    "strike_rate_train = 100*sum([np.abs(x)<=check for x in err_train])/len(err_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test strike rate : 87.92401628222524\n",
      "Train strike rate : 88.80962995987517\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# printint the results\n",
    "print(\"Test strike rate : {}\\nTrain strike rate : {}\".format(strike_rate_test,strike_rate_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
